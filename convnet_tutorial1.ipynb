{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "convnet_tutorial1.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/akhti/ammi-2019-ConvNets/blob/master/convnet_tutorial1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "mCt-frpFH8oN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The tutorials use PyTorch. You will need to load the following dependencies."
      ]
    },
    {
      "metadata": {
        "id": "hqnl0AKVXIA4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "import PIL\n",
        "import imageio\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import skimage.transform\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.utils.data\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "from IPython import display\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CKeYuM-cIXxs",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The code below may be helpful in visualizing PyTorch tensors as images."
      ]
    },
    {
      "metadata": {
        "id": "ZZd_rI8edYIB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "\n",
        "def show(img):\n",
        "    \"\"\"Show PyTorch tensor img as an image in matplotlib.\"\"\"\n",
        "    npimg = img.cpu().detach().numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1,2,0)), interpolation='nearest')\n",
        "    plt.grid(False)\n",
        "    plt.gca().axis('off')\n",
        "\n",
        "def display_thumb(img):\n",
        "  display.display(transforms.Resize(128)(img))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dzfEE578uSNp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "71LRkRxndajG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## First tutorial:\n",
        "\n",
        "In the first tutorial, we are going to train a logistic regressor on the MNIST dataset of handwritten digits. Next, we will turn this logistic regressor into a non-linear convolutional network.\n",
        "\n",
        "The following code will load the MNIST dataset. Run it and inspect some of the images and their labels to confirm they are correct.\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "GX_ky5qC--uv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Load the training and test dataset.\n",
        "mnist_train = datasets.MNIST('/tmp/mnist', train=True, download=True)\n",
        "mnist_test = datasets.MNIST('/tmp/mnist', train=False, download=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "E8dy7-kBHwco",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Show a random image and the corresponding target.\n",
        "img, target = mnist_train[0]\n",
        "print('Label of image:', mnist_train.classes[target])\n",
        "img"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aKbXgidhWr6L",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Next, we create a PyTorch dataloader for the MNIST dataset."
      ]
    },
    {
      "metadata": {
        "id": "ay0iiI1kWyMC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# This ensures the MNIST dataset produces PyTorch tensors.\n",
        "mnist_train.transform = transforms.ToTensor()\n",
        "mnist_test.transform = transforms.ToTensor()\n",
        "\n",
        "# Size of the batches the data loader will produce.\n",
        "batch_size = 64\n",
        "\n",
        "# This creates the dataloaders.\n",
        "train_loader = torch.utils.data.DataLoader(mnist_train, batch_size=batch_size, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(mnist_test, batch_size=batch_size, shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "liekFZzvYX9E",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Next, implement a logistic regression model in PyTorch. Note that a logistic regressor uses a linear transformation of the input.\n"
      ]
    },
    {
      "metadata": {
        "id": "zEw5YorSYkWF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class LogisticRegression(nn.Module):\n",
        "  \"\"\"Linear logistic regression model.\"\"\"\n",
        "  \n",
        "  def __init__(self, input_size, num_classes):\n",
        "    super().__init__()\n",
        "    ###########################################################################\n",
        "    # TODO: Instantiate the layer here.                                       #\n",
        "    ###########################################################################\n",
        "    \n",
        "  def forward(self, x):\n",
        "    ###########################################################################\n",
        "    # TODO: Apply the layer to the input.                                     #\n",
        "    ###########################################################################\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HCerRXDHZFAS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We will use the following generic training loop for a PyTorch model."
      ]
    },
    {
      "metadata": {
        "id": "qVyEKl3OZLJw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train(model, criterion, data_loader, optimizer, num_epochs):\n",
        "    \"\"\"Simple training loop for a PyTorch model.\"\"\"\n",
        "    \n",
        "    # Make sure model is in training mode.\n",
        "    model.train()\n",
        "    # Move model to the device.\n",
        "    model.to(device)\n",
        "    \n",
        "    # Exponential moving average of the loss.\n",
        "    ema_loss = None\n",
        "    \n",
        "    # Loop over epochs.\n",
        "    for epoch in range(num_epochs):\n",
        "      \n",
        "      # Loop over data.\n",
        "      for batch_idx, (data, target) in enumerate(data_loader):\n",
        "          data = data.to(device)\n",
        "          target = target.to(device)\n",
        "        \n",
        "          # Forward pass.\n",
        "          output = model(data)\n",
        "          loss = criterion(output, target)\n",
        "          \n",
        "          # Backward pass.\n",
        "          optimizer.zero_grad()\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "          \n",
        "          if ema_loss is None:\n",
        "            ema_loss = loss.item()\n",
        "          else:\n",
        "            ema_loss += (loss.item() - ema_loss) * 0.01 \n",
        "          \n",
        "          # Print out progress.\n",
        "          if batch_idx % 500 == 0:\n",
        "              print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                    epoch, batch_idx * len(data), \n",
        "                    len(data_loader.dataset),\n",
        "                    100. * batch_idx / len(data_loader), ema_loss),\n",
        "              )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oN8qTuGkZ-3X",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Question:** For the model you are currently using, is there any difference between using the model in `train` mode or using it in `eval` mode? \n",
        "\n",
        "Create an SGD optimizer and us it to train the logistic regressor on the MNIST training data for a few epochs. What loss function do you need to use?"
      ]
    },
    {
      "metadata": {
        "id": "kC3z31pvadeP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Create model, criterion, and optimizer.\n",
        "model = LogisticRegression(28 * 28, 10)\n",
        "###########################################################################\n",
        "# TODO: Create criterion and optimize here.                               #\n",
        "###########################################################################\n",
        "criterion = None\n",
        "optimizer = None\n",
        "\n",
        "# Train the model. If everything is correct, the loss should go below 0.45.\n",
        "train(model, criterion, train_loader, optimizer, num_epochs=5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "x0QN7Mhiar7d",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Visualize the weights of the trained model. What do you see? Why?"
      ]
    },
    {
      "metadata": {
        "id": "gxletH44a4MX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "assert model.linear.weight.shape == (10, 28 * 28)\n",
        "show(torchvision.utils.make_grid(\n",
        "    model.linear.weight.view(10, 1, 28, 28),\n",
        "    normalize=True,\n",
        "    nrow=5,\n",
        "))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Lxf5NxQ6a5cT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Use the following function to measure the test accuracy of your trained model."
      ]
    },
    {
      "metadata": {
        "id": "8UYWbqZYa9Qr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def test(model, data_loader):\n",
        "    \"\"\"Measures the accuracy of a model on a data set.\"\"\"\n",
        "    \n",
        "    # Make sure the model is in evaluation mode.\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "\n",
        "    # We do not need to maintain intermediate activations while testing.\n",
        "    with torch.no_grad():\n",
        "      \n",
        "        # Loop over test data.\n",
        "        for data, target in data_loader:\n",
        "          \n",
        "            # Forward pass.\n",
        "            output = model(data.to(device))\n",
        "            \n",
        "            # Get the label corresponding to the highest predicted probability.\n",
        "            pred = output.argmax(dim=1, keepdim=True)\n",
        "            \n",
        "            # Count number of correct predictions.\n",
        "            correct += pred.cpu().eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    # Print test accuracy.\n",
        "    print('Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "          correct, \n",
        "          len(data_loader.dataset),\n",
        "          100. * correct / len(data_loader.dataset)),\n",
        "    )  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MrEY_dy5AKQV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Accuracy should be around 90%.\n",
        "test(model, test_loader)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "g1DV-MS2bxYq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Question:** To have the logistic regressor output probabilities, they need to be processed through a softmax layer. Implement a softmax layer yourself. What numerical issues may arise in this layer? How can you solve them? Use the testing code to confirm you implemented it correctly."
      ]
    },
    {
      "metadata": {
        "id": "Dj4X2PnOfK9W",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def bad_softmax(logits):\n",
        "  \"\"\"Computes softmax in a naive manner.\"\"\"\n",
        "  probs = logits.exp()\n",
        "  probs /= probs.sum(-1, keepdim=True)\n",
        "  return probs\n",
        "\n",
        "def good_softmax(logits):\n",
        "  \"\"\"Computes softmax in a numerically safe manner.\"\"\"\n",
        "  ###########################################################################\n",
        "  # TODO: Implement a more stable way to compute softmax                    #\n",
        "  ###########################################################################  \n",
        "  return probs\n",
        "\n",
        "\n",
        "# Test the new softmax layer.\n",
        "logits = torch.rand((1, 20)) + 100\n",
        "print(bad_softmax(logits).sum(), \n",
        "      good_softmax(logits).sum())  # by definition, the correct value is 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4C_J5S0RScXJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Because of numerical issues like the one you just experiences, PyTorch code typically uses a `LogSoftmax` layer."
      ]
    },
    {
      "metadata": {
        "id": "lgStX-ctjIms",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Question [optional]:** PyTorch automatically computes the backpropagation gradient of a module for you. However, it can be instructive to derive and implement your own backward function. Try and implement the backward function for your softmax module and confirm that it is correct."
      ]
    },
    {
      "metadata": {
        "id": "P0xTuXo3dyWH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "We will now replace the logistic regressor by a small convolutional network with two convolutional layers and a linear layer, and ReLU activations in between the layers. Implement the model and use the same functions as before to train and test the convolutional network."
      ]
    },
    {
      "metadata": {
        "id": "vg4CO_WDeLqh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class ConvolutionalNetwork(nn.Module):\n",
        "  \"\"\"Simple convolutional network.\"\"\"\n",
        "  \n",
        "  def __init__(self, image_side_size, num_classes, in_channels=1):\n",
        "      super(ConvolutionalNetwork, self).__init__()\n",
        "      # Fill these in:\n",
        "      ##########################################################################\n",
        "      # TODO: Implement a convulutional and a linear part.                     #\n",
        "      # Hint: see forward() to understand how they should work together.       #\n",
        "      # Hint: the following may be useful: nn.Conv2d, nn.MaxPool2d.            #\n",
        "      ##########################################################################\n",
        "      self.conv_network = None\n",
        "      self.linear = None\n",
        "      \n",
        "  def forward(self, x):\n",
        "      x = self.conv_network(x)\n",
        "      x = self.linear(x.view(x.size(0), -1))\n",
        "      return x\n",
        "\n",
        "    \n",
        "# Create and train convolutional network.\n",
        "# The accuracy should be around 98%.\n",
        "conv_model = ConvolutionalNetwork(28, 10)\n",
        "###########################################################################\n",
        "# TODO: Create criterion and optimize here.                               #\n",
        "###########################################################################\n",
        "criterion = None\n",
        "optimizer = None\n",
        "train(conv_model, criterion, train_loader, optimizer, num_epochs=5)\n",
        "test(conv_model, test_loader)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EgLLXSScfwqK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Inspect the filters in the first layer of the trained convolutional network. What do they look like? Why?"
      ]
    },
    {
      "metadata": {
        "id": "Ye1xcjUif4e-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "first_conv = list(conv_model.conv_network.children())[0]\n",
        "show(torchvision.utils.make_grid(\n",
        "    first_conv.weight,\n",
        "    normalize=True,\n",
        "    nrow=8,\n",
        "))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ncHkdY3df6R7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Question [optional]:** Implement your own version of forward pass of nn.Conv2d in numpy **without** using any of pre-defined convolutional functions."
      ]
    },
    {
      "metadata": {
        "id": "RV30kha3vSsC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def conv_forward_naive(x, w, b, conv_param):\n",
        "    \"\"\"\n",
        "    A naive Python implementation of a convolutional layer.\n",
        "    The input consists of N data points, each with C channels, height H and\n",
        "    width W. We convolve each input with F different filters, where each filter\n",
        "    spans all C channels and has height HH and width WW.\n",
        "    Input:\n",
        "    - x: Input data of shape (N, C, H, W)\n",
        "    - w: Filter weights of shape (F, C, HH, WW)\n",
        "    - b: Biases, of shape (F,)\n",
        "    - conv_param: A dictionary with the following keys:\n",
        "      - 'stride': The number of pixels between adjacent receptive fields in the\n",
        "        horizontal and vertical directions.\n",
        "      - 'pad': The number of pixels that will be used to zero-pad the input. \n",
        "        \n",
        "    During padding, 'pad' zeros should be placed symmetrically (i.e equally on both sides)\n",
        "    along the height and width axes of the input. Be careful not to modfiy the original\n",
        "    input x directly.\n",
        "    Returns an array.\n",
        "    - out: Output data, of shape (N, F, H', W') where H' and W' are given by\n",
        "      H' = 1 + (H + 2 * pad - HH) / stride\n",
        "      W' = 1 + (W + 2 * pad - WW) / stride\n",
        "    \"\"\"\n",
        "    out = None\n",
        "\n",
        "    N, C, H, W = x.shape\n",
        "    num_filters, _, filter_height, filter_width = w.shape\n",
        "    stride, pad = conv_param['stride'], conv_param['pad']\n",
        "\n",
        "    # Check dimensions.\n",
        "    assert (W + 2 * pad - filter_width) % stride == 0, 'width does not work'\n",
        "    assert (H + 2 * pad - filter_height) % stride == 0, 'height does not work'\n",
        "\n",
        "    ###########################################################################\n",
        "    # TODO: Implement the convolutional forward pass (in numpy).              #\n",
        "    # Hint: you can use the function np.pad for padding.                      #\n",
        "    ###########################################################################\n",
        "    return out\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6dDNQP8VvVVj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "You can test your implementation by running the following:"
      ]
    },
    {
      "metadata": {
        "id": "7Leww6XRuC_0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Make convolution module.\n",
        "w_shape = (3, 3, 4, 4)\n",
        "w = np.linspace(-0.2, 0.3, num=np.prod(w_shape)).reshape(w_shape)\n",
        "b = np.linspace(-0.1, 0.2, num=3)\n",
        "\n",
        "# Compute output of module and compare against reference values.\n",
        "x_shape = (2, 3, 4, 4)\n",
        "x = np.linspace(-0.1, 0.5, num=np.prod(x_shape)).reshape(x_shape)\n",
        "out = conv_forward_naive(x, w, b, {'stride': 2, 'pad': 1})\n",
        "\n",
        "correct_out = np.array([[[[-0.08759809, -0.10987781],\n",
        "                           [-0.18387192, -0.2109216 ]],\n",
        "                          [[ 0.21027089,  0.21661097],\n",
        "                           [ 0.22847626,  0.23004637]],\n",
        "                          [[ 0.50813986,  0.54309974],\n",
        "                           [ 0.64082444,  0.67101435]]],\n",
        "                         [[[-0.98053589, -1.03143541],\n",
        "                           [-1.19128892, -1.24695841]],\n",
        "                          [[ 0.69108355,  0.66880383],\n",
        "                           [ 0.59480972,  0.56776003]],\n",
        "                          [[ 2.36270298,  2.36904306],\n",
        "                           [ 2.38090835,  2.38247847]]]])\n",
        "\n",
        "# Compare your output to ours; difference should be around e-8\n",
        "print('Testing conv_forward_naive')\n",
        "rel_error = ((out - correct_out) / (out + correct_out + 1e-6)).mean()\n",
        "print('difference: ', rel_error)\n",
        "assert abs(rel_error) < 1e-6, 'Something is wrong'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4c_Whyy2ysdF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Aside: Image processing via convolutions:**\n",
        "\n",
        "As fun way to both check your implementation and gain a better understanding of the type of operation that convolutional layers can perform, we will set up an input containing two images and manually set up filters that perform common image processing operations (grayscale conversion and edge detection). The convolution forward pass will apply these operations to each of the input images. We can then visualize the results as a sanity check."
      ]
    },
    {
      "metadata": {
        "id": "SygERdfdv6U-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# TODO(anton): this should work even without completing conv2d-by-hand.\n",
        "# Load image of a kitten and a puppy.\n",
        "kitten_uri = \"https://upload.wikimedia.org/wikipedia/commons/thumb/1/1b/Persian_Cat_%28kitten%29.jpg/256px-Persian_Cat_%28kitten%29.jpg\"\n",
        "puppy_uri = \"https://upload.wikimedia.org/wikipedia/commons/thumb/6/6e/Golde33443.jpg/256px-Golde33443.jpg\"\n",
        "kitten, puppy = imageio.imread(kitten_uri), imageio.imread(puppy_uri)\n",
        "\n",
        "img_size = 200   # Make this smaller if it runs too slow\n",
        "x = np.zeros((2, 3, img_size, img_size))\n",
        "x[0, :, :, :] = skimage.transform.resize(puppy, (img_size, img_size)).transpose((2, 0, 1))\n",
        "x[1, :, :, :] = skimage.transform.resize(kitten, (img_size, img_size)).transpose((2, 0, 1))\n",
        "\n",
        "# Set up a convolutional weights holding 2 filters, each 3x3\n",
        "w = np.zeros((2, 3, 3, 3))\n",
        "\n",
        "# The first filter converts the image to grayscale.\n",
        "# Set up the red, green, and blue channels of the filter.\n",
        "w[0, 0, :, :] = [[0, 0, 0], [0, 0.3, 0], [0, 0, 0]]\n",
        "w[0, 1, :, :] = [[0, 0, 0], [0, 0.6, 0], [0, 0, 0]]\n",
        "w[0, 2, :, :] = [[0, 0, 0], [0, 0.1, 0], [0, 0, 0]]\n",
        "\n",
        "# Second filter detects horizontal edges in the blue channel.\n",
        "w[1, 2, :, :] = [[1, 2, 1], [0, 0, 0], [-1, -2, -1]]\n",
        "\n",
        "# Vector of biases. We don't need any bias for the grayscale\n",
        "# filter, but for the edge detection filter we want to add 128\n",
        "# to each output so that nothing is negative.\n",
        "b = np.array([0, 128])\n",
        "\n",
        "# Compute the result of convolving each input in x with each filter in w,\n",
        "# offsetting by b, and storing the results in out.\n",
        "out = nn.functional.conv2d(\n",
        "    torch.FloatTensor(x), torch.FloatTensor(w), torch.FloatTensor(b),\n",
        "    stride=1, padding=1).numpy()\n",
        "\n",
        "def imshow_noax(img, normalize=True):\n",
        "    \"\"\"Tiny helper to show images as uint8 and remove axis labels.\"\"\"\n",
        "    if normalize:\n",
        "        img_max, img_min = np.max(img), np.min(img)\n",
        "        img = 255.0 * (img - img_min) / (img_max - img_min)\n",
        "    plt.imshow(img.astype('uint8'))\n",
        "    plt.gca().axis('off')\n",
        "\n",
        "# Show the original images and the results of the conv operation\n",
        "plt.subplot(2, 3, 1)\n",
        "imshow_noax(puppy, normalize=False)\n",
        "plt.title('Original image')\n",
        "plt.subplot(2, 3, 2)\n",
        "imshow_noax(out[0, 0])\n",
        "plt.title('Grayscale')\n",
        "plt.subplot(2, 3, 3)\n",
        "imshow_noax(out[0, 1])\n",
        "plt.title('Edges')\n",
        "plt.subplot(2, 3, 4)\n",
        "imshow_noax(kitten, normalize=False)\n",
        "plt.subplot(2, 3, 5)\n",
        "imshow_noax(out[1, 0])\n",
        "plt.subplot(2, 3, 6)\n",
        "imshow_noax(out[1, 1])\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
